#!/usr/bin/env python3
"""
chunksummary.py

Post-processing after reworkingthetext.py.

This script:
  1) Summarizes all figure captions (1–2 sentences each)
  2) Summarizes supplementary material (chunk-by-chunk + global 1-sentence per section)
  3) Summarizes the main text (double reading: context + final summary)
     - Uses figure summaries to enrich context if figures are mentioned
     - Mentions supplementary sections if related

Outputs are written to summaries/ subdirectory.
"""

import os
import json
from langchain_ollama import OllamaLLM
from typing import List

# ---------------- CONFIG ----------------
BASE_DIR = os.path.expanduser("~/ai_data/Journal_Club/First")
MAIN_DIR = os.path.join(BASE_DIR, "main_article")
OUT_DIR = os.path.join(BASE_DIR, "summaries")
os.makedirs(OUT_DIR, exist_ok=True)

LLM_MODEL = "llama3.1"
llm = OllamaLLM(model=LLM_MODEL)

# Paths to text parts generated by reworkingthetext.py
MAIN_TEXT_PATH = os.path.join(MAIN_DIR, "body_cleaned.txt")
SUPP_SECTIONS_DIR = os.path.join(MAIN_DIR, "supplementary_sections")
FIGURES_DIR = os.path.join(MAIN_DIR, "figures")
FIGURE_CAPTIONS = [os.path.join(FIGURES_DIR, f) for f in sorted(os.listdir(FIGURES_DIR)) if f.endswith(".txt")]

# Output files
FIG_SUMMARY_PATH = os.path.join(OUT_DIR, "figure_summaries.json")
SUPP_SUMMARY_PATH = os.path.join(OUT_DIR, "supplementary_summary.json")
MAIN_CHUNKS_DIR = os.path.join(OUT_DIR, "main_chunks")
os.makedirs(MAIN_CHUNKS_DIR, exist_ok=True)


# ---------------- Utility functions ----------------
def read_file(path):
    if not os.path.exists(path):
        return ""
    with open(path, "r", encoding="utf-8") as f:
        return f.read()


def write_file(path, text):
    with open(path, "w", encoding="utf-8") as f:
        f.write(text)


def sliding_chunks(text: str, size: int, overlap: int) -> List[str]:
    step = size - overlap
    return [text[i:i + size] for i in range(0, max(len(text) - overlap, 1), step)]


# ---------------- STEP 1: Figure Summaries ----------------
def summarize_figures():
    print("STEP 1 — Summarizing figures...")
    figure_summaries = {}

    for fpath in FIGURE_CAPTIONS:
        caption = read_file(fpath)
        if not caption.strip():
            continue
        prompt = f"""Summarize this figure caption in 1–2 sentences.
Be precise about what is being shown and what phenomenon, parameter, or experiment it illustrates.

FIGURE CAPTION:
\"\"\"{caption[:2500]}\"\"\""""
        summary = llm.invoke(prompt).strip()
        figure_summaries[os.path.basename(fpath)] = summary

    write_file(FIG_SUMMARY_PATH, json.dumps(figure_summaries, indent=2, ensure_ascii=False))
    print(f"✅ Figure summaries saved to {FIG_SUMMARY_PATH}")
    return figure_summaries


# ---------------- STEP 2: Supplementary Summaries ----------------
def summarize_supplementary():
    print("STEP 2 — Summarizing supplementary material...")

    # Get all section files in numerical order
    section_files = sorted(
        [f for f in os.listdir(SUPP_SECTIONS_DIR) if f.endswith(".txt")],
        key=lambda x: int(x.split("_")[0]) if x.split("_")[0].isdigit() else 999
    )

    summaries = {}
    CHUNK_SIZE_SUPP = 4000
    CHUNK_OVERLAP_SUPP = 400
    SUPP_CHUNKS_DIR = os.path.join(OUT_DIR, "supplementary_chunks")
    os.makedirs(SUPP_CHUNKS_DIR, exist_ok=True)

    for s_idx, sec_file in enumerate(section_files, start=1):
        section_text = read_file(os.path.join(SUPP_SECTIONS_DIR, sec_file))
        section_chunks = sliding_chunks(section_text, CHUNK_SIZE_SUPP, CHUNK_OVERLAP_SUPP)
        sec_chunk_summaries = []
        prev_context = "START OF SECTION"

        print(f"  Summarizing supplementary section {s_idx} ({len(section_chunks)} chunks)...")

        for c_idx, chunk in enumerate(section_chunks, start=1):
            context_prompt = f"""Previous chunk summary: {prev_context}

You are reading a scientific supplementary section.
In 1–2 sentences, explain where we are in the explanation or procedure.
CHUNK:
{chunk[:1500]}"""
            context_resp = llm.invoke(context_prompt)

            summary_prompt = f"""Summarize this supplementary chunk in 3–5 sentences,
focusing on what is being measured, calculated, or derived.

CONTEXT: {context_resp}
CHUNK:
{chunk[:4000]}"""
            summary_resp = llm.invoke(summary_prompt).strip()
            prev_context = summary_resp
            sec_chunk_summaries.append(summary_resp)

            # Save individual chunk
            outpath = os.path.join(SUPP_CHUNKS_DIR, f"section_{s_idx:02d}_chunk_{c_idx:03d}.txt")
            write_file(outpath, summary_resp)

        # Join chunk summaries safely outside f-string
        joined_chunks = "\n".join(sec_chunk_summaries)
        global_prompt = f"""You are a scientific summarizer.
Below are all chunk summaries from one supplementary section.
Summarize the entire section in ONE precise sentence describing what it investigates or concludes.

CHUNK SUMMARIES:
{joined_chunks}"""
        global_summary = llm.invoke(global_prompt)
        summaries[f"section_{s_idx}"] = global_summary.strip()

    write_file(SUPP_SUMMARY_PATH, json.dumps(summaries, indent=2, ensure_ascii=False))
    print(f"✅ Supplementary summaries saved to {SUPP_SUMMARY_PATH}")
    return summaries


# ---------------- STEP 3: Main Text Summaries ----------------
def summarize_main(figure_summaries, supp_summaries):
    print("STEP 3 — Summarizing main text (context-aware)...")
    text = read_file(MAIN_TEXT_PATH)
    if not text.strip():
        print("⚠️ No main text found.")
        return

    CHUNK_SIZE = 5000
    CHUNK_OVERLAP = 500
    chunks = sliding_chunks(text, CHUNK_SIZE, CHUNK_OVERLAP)

    prev_context = "START OF PAPER"
    figure_refs = {k.lower(): v for k, v in figure_summaries.items()}

    for i, ch in enumerate(chunks, start=1):
        # detect figure mentions
        mentioned_figures = [name for name in figure_refs.keys() if name.replace(".txt", "").lower() in ch.lower()]
        fig_notes = "\n".join([f"Note: this chunk discusses {name} → {figure_refs[name]}" for name in mentioned_figures]) or "No direct figure mentioned."

        # detect supplementary link
        supp_note = ""
        for s_id, s_summary in supp_summaries.items():
            if any(word in ch.lower() for word in s_summary.lower().split()[:6]):
                supp_note = f"This relates to supplementary {s_id}: {s_summary}"
                break
        if not supp_note:
            supp_note = "No clear supplementary link."

        # pass 1 – context understanding
        context_prompt = f"""Previous chunk summary: {prev_context}
You are reading a scientific article.
Explain briefly (1–2 sentences) where we are in the structure of the paper.

CHUNK:
{ch[:1500]}"""
        context_resp = llm.invoke(context_prompt)

        # pass 2 – contextual summary
        summary_prompt = f"""Summarize the following chunk in 5–8 sentences,
including technical and conceptual points. If figures or supplementary work are relevant, mention them.

FIGURE INFO:
{fig_notes}

SUPPLEMENTARY INFO:
{supp_note}

CONTEXT:
{context_resp}

CHUNK:
{ch[:4000]}"""
        summary_resp = llm.invoke(summary_prompt).strip()
        prev_context = summary_resp
        write_file(os.path.join(MAIN_CHUNKS_DIR, f"chunk_{i:03d}.txt"), summary_resp)

    print(f"✅ Main text chunk summaries saved to {MAIN_CHUNKS_DIR}")


# ---------------- Main Runner ----------------
def main():
    print("Starting chunksummary.py pipeline...")
    figure_summaries = summarize_figures()
    supp_summaries = summarize_supplementary()
    summarize_main(figure_summaries, supp_summaries)
    print("Pipeline complete. ✅")


if __name__ == "__main__":
    main()
