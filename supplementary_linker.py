#!/usr/bin/env python3
"""
supplementary_linker.py

Goal:
1. Read supplementary chunk summaries (like we did for main paper chunks)
2. Produce a global "one-sentence-per-section" summary
3. For every slide plan file, decide if supplementary adds value
4. Append one new line to each slide file if relevant:
        "Supplementary can enhance this slide: <reason/keyword>"

This does NOT rewrite slides ‚Äî it only appends usable linking notes.
"""

import re
from pathlib import Path
from typing import List, Optional
from langchain_core.language_models import BaseLanguageModel
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain.prompts import PromptTemplate


# ================================================================
# Step 1 ‚Äì Convert supplementary chunks ‚Üí one-sentence summaries
# ================================================================
def generate_supplementary_overview(
        chunks_dir: str,
        output_file: str,
        llm: BaseLanguageModel
    ) -> List[str]:
    """
    For each supplementary summary chunk:
    ‚Üí produce ONE sentence describing what that section adds.
    """

    chunks = sorted(Path(chunks_dir).glob("*.txt"))
    results = []

    print(f"üìÑ Found {len(chunks)} supplementary files")

    prompt = PromptTemplate.from_template("""
You summarize supplementary sections of a physics paper.
Return exactly ONE sentence that captures *what new or deeper information
this supplementary part contributes beyond the main text*.

Rules:
‚Ä¢ max 28 words, one sentence only
‚Ä¢ must reflect what is *added*, *extended*, or *explained*
‚Ä¢ NO meta-text ("this file says")
‚Ä¢ NO bullet points, only a sentence

Text:
\"\"\"{text}\"\"\"

Return one sentence:
""")

    for file in chunks:
        content = file.read_text()

        one_line = llm.invoke(prompt.format(text=content)).strip()
        results.append(one_line)

        print(f"‚úì {file.name} ‚Üí {one_line}")

    Path(output_file).write_text("\n".join(results))
    return results



# ================================================================
# Step 2 ‚Äì Match supplementary content to slide plans
# ================================================================
def link_supplementary_to_slides(
        supplementary_sentences: List[str],
        slides_dir: str,
        llm: BaseLanguageModel
    ):
    """
    For each slide .txt generated by the plan:
    ‚Üí ask LLM: does supplementary help this one?
    ‚Üí If yes, append a new final line:

            [SupMat] Additional insight available ‚Äî <short reason>

    Printed to terminal as applied.
    """

    slide_files = sorted(Path(slides_dir).glob("*.txt"))
    print(f"\nüîç Checking {len(slide_files)} slide files for enrichment...")

    decision_prompt = PromptTemplate.from_template("""
You decide if supplementary information improves a slide.

Slide content:
\"\"\"{slide}\"\"\"

Supplementary points:
{supp}

Task:
‚Ä¢ If supplementary does NOT add meaning ‚Üí return exactly: NO
‚Ä¢ If it helps ‚Üí return ONE short phrase explaining HOW (~6‚Äì12 words)

Examples of good answers:
    "clarifies atomic loss mechanism"
    "adds mathematical derivation of g2 behavior"
    "details calibration of cavity lock"

Return:
If no ‚Üí "NO"
If yes ‚Üí ONLY the short phrase (no full sentences)
""")

    for slide in slide_files:
        content = slide.read_text()
        supp = "\n".join(f"- {s}" for s in supplementary_sentences[:10])  # cap to avoid overload

        result = llm.invoke(
            decision_prompt.format(slide=content, supp=supp)
        ).strip()

        if result == "NO":
            print(f"‚Äì slide {slide.name}: no useful supplementary link")
            continue

        update_line = f"[SupMat] Additional insight available ‚Äî {result}\n"

        with open(slide, "a") as f:
            f.write("\n" + update_line)

        print(f"‚ú® UPDATED {slide.name} ‚Üí {update_line.strip()}")


# ================================================================
# Public Runner
# ================================================================
def integrate_supplementary(
        chunks_dir: str,
        summary_output_file: str,
        slides_dir: str,
        llm: BaseLanguageModel
    ):
    """Pipeline = summarize supplementary ‚Üí link slides automatically"""
    overview = generate_supplementary_overview(chunks_dir, summary_output_file, llm)
    link_supplementary_to_slides(overview, slides_dir, llm)
    print("\nüöÄ Supplementary integration complete.")


# ================================================================
# CLI (optional)
# ================================================================
if __name__ == "__main__":
    import sys
    from langchain_ollama import OllamaLLM

    if len(sys.argv) < 4:
        print("usage: python supplementary_linker.py <supp_chunks_dir> <overview_out> <slides_dir>")
        exit()

    llm = OllamaLLM(model="llama3.1:latest")  # modify if needed

    integrate_supplementary(
        chunks_dir=sys.argv[1],
        summary_output_file=sys.argv[2],
        slides_dir=sys.argv[3],
        llm=llm
    )
